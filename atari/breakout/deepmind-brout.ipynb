{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,685,667\n",
      "Trainable params: 1,685,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 20, 20, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,685,667\n",
      "Trainable params: 1,685,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "INFO:tensorflow:Summary name Total Reward/Episode is illegal; using Total_Reward/Episode instead.\n",
      "INFO:tensorflow:Summary name Average Max Q/Episode is illegal; using Average_Max_Q/Episode instead.\n",
      "INFO:tensorflow:Summary name Average Loss/Episode is illegal; using Average_Loss/Episode instead.\n",
      "WARNING:tensorflow:From /home/ericnjin/anaconda3/envs/deep-learning-with-python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "episode: 0   score: 0.0   memory length: 104   epsilon: 1.0   global_step: 104   average_q: 0.029282542912719343   average loss: 0.0\n",
      "episode: 1   score: 2.0   memory length: 281   epsilon: 1.0   global_step: 281   average_q: 0.027283729669653763   average loss: 0.0\n",
      "episode: 2   score: 2.0   memory length: 459   epsilon: 1.0   global_step: 459   average_q: 0.02877752926577343   average loss: 0.0\n",
      "episode: 3   score: 1.0   memory length: 580   epsilon: 1.0   global_step: 580   average_q: 0.02768508786689644   average loss: 0.0\n",
      "episode: 4   score: 0.0   memory length: 698   epsilon: 1.0   global_step: 698   average_q: 0.02893721514334113   average loss: 0.0\n",
      "episode: 5   score: 1.0   memory length: 855   epsilon: 1.0   global_step: 855   average_q: 0.027631836984852318   average loss: 0.0\n",
      "episode: 6   score: 1.0   memory length: 1004   epsilon: 1.0   global_step: 1004   average_q: 0.029028682688238636   average loss: 0.0\n",
      "episode: 7   score: 2.0   memory length: 1225   epsilon: 1.0   global_step: 1225   average_q: 0.02960986633072881   average loss: 0.0\n",
      "episode: 8   score: 4.0   memory length: 1516   epsilon: 1.0   global_step: 1516   average_q: 0.02830617232216183   average loss: 0.0\n",
      "episode: 9   score: 5.0   memory length: 1826   epsilon: 1.0   global_step: 1826   average_q: 0.029379717338710063   average loss: 0.0\n",
      "episode: 10   score: 0.0   memory length: 1947   epsilon: 1.0   global_step: 1947   average_q: 0.029359974321131865   average loss: 0.0\n",
      "episode: 11   score: 1.0   memory length: 2095   epsilon: 1.0   global_step: 2095   average_q: 0.028891198387419856   average loss: 0.0\n",
      "episode: 12   score: 0.0   memory length: 2204   epsilon: 1.0   global_step: 2204   average_q: 0.029257618215516073   average loss: 0.0\n",
      "episode: 13   score: 2.0   memory length: 2394   epsilon: 1.0   global_step: 2394   average_q: 0.02744355487000001   average loss: 0.0\n",
      "episode: 14   score: 1.0   memory length: 2535   epsilon: 1.0   global_step: 2535   average_q: 0.028823966133996105   average loss: 0.0\n",
      "episode: 15   score: 1.0   memory length: 2681   epsilon: 1.0   global_step: 2681   average_q: 0.028678049703371036   average loss: 0.0\n",
      "episode: 16   score: 1.0   memory length: 2842   epsilon: 1.0   global_step: 2842   average_q: 0.028908662220335894   average loss: 0.0\n",
      "episode: 17   score: 2.0   memory length: 3020   epsilon: 1.0   global_step: 3020   average_q: 0.028264668278312415   average loss: 0.0\n",
      "episode: 18   score: 0.0   memory length: 3137   epsilon: 1.0   global_step: 3137   average_q: 0.029303695178694196   average loss: 0.0\n",
      "episode: 19   score: 1.0   memory length: 3293   epsilon: 1.0   global_step: 3293   average_q: 0.029260114778597385   average loss: 0.0\n",
      "episode: 20   score: 1.0   memory length: 3460   epsilon: 1.0   global_step: 3460   average_q: 0.029050606598486444   average loss: 0.0\n",
      "episode: 21   score: 0.0   memory length: 3585   epsilon: 1.0   global_step: 3585   average_q: 0.029247384250164033   average loss: 0.0\n",
      "episode: 22   score: 2.0   memory length: 3784   epsilon: 1.0   global_step: 3784   average_q: 0.028677612440145793   average loss: 0.0\n",
      "episode: 23   score: 0.0   memory length: 3902   epsilon: 1.0   global_step: 3902   average_q: 0.029361351535229358   average loss: 0.0\n",
      "episode: 24   score: 1.0   memory length: 4050   epsilon: 1.0   global_step: 4050   average_q: 0.028300644401964302   average loss: 0.0\n",
      "episode: 25   score: 0.0   memory length: 4154   epsilon: 1.0   global_step: 4154   average_q: 0.029294438767605104   average loss: 0.0\n",
      "episode: 26   score: 0.0   memory length: 4270   epsilon: 1.0   global_step: 4270   average_q: 0.02927431226547422   average loss: 0.0\n",
      "episode: 27   score: 1.0   memory length: 4426   epsilon: 1.0   global_step: 4426   average_q: 0.0287924728427942   average loss: 0.0\n",
      "episode: 28   score: 0.0   memory length: 4541   epsilon: 1.0   global_step: 4541   average_q: 0.029291941549467005   average loss: 0.0\n",
      "episode: 29   score: 1.0   memory length: 4675   epsilon: 1.0   global_step: 4675   average_q: 0.027427752488362257   average loss: 0.0\n",
      "episode: 30   score: 1.0   memory length: 4801   epsilon: 1.0   global_step: 4801   average_q: 0.028194374286584438   average loss: 0.0\n",
      "episode: 31   score: 0.0   memory length: 4894   epsilon: 1.0   global_step: 4894   average_q: 0.029370638992517226   average loss: 0.0\n",
      "episode: 32   score: 0.0   memory length: 5012   epsilon: 1.0   global_step: 5012   average_q: 0.029113294809299   average loss: 0.0\n",
      "episode: 33   score: 1.0   memory length: 5164   epsilon: 1.0   global_step: 5164   average_q: 0.028352944903369797   average loss: 0.0\n",
      "episode: 34   score: 2.0   memory length: 5358   epsilon: 1.0   global_step: 5358   average_q: 0.029284240409117385   average loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 35   score: 2.0   memory length: 5575   epsilon: 1.0   global_step: 5575   average_q: 0.028277389962689668   average loss: 0.0\n",
      "episode: 36   score: 0.0   memory length: 5677   epsilon: 1.0   global_step: 5677   average_q: 0.029275660585685103   average loss: 0.0\n",
      "episode: 37   score: 1.0   memory length: 5824   epsilon: 1.0   global_step: 5824   average_q: 0.028513695461814908   average loss: 0.0\n",
      "episode: 38   score: 1.0   memory length: 5980   epsilon: 1.0   global_step: 5980   average_q: 0.02876131084914773   average loss: 0.0\n",
      "episode: 39   score: 1.0   memory length: 6123   epsilon: 1.0   global_step: 6123   average_q: 0.027591534779517802   average loss: 0.0\n",
      "episode: 40   score: 4.0   memory length: 6392   epsilon: 1.0   global_step: 6392   average_q: 0.028619189583956088   average loss: 0.0\n",
      "episode: 41   score: 3.0   memory length: 6599   epsilon: 1.0   global_step: 6599   average_q: 0.027524414755727932   average loss: 0.0\n",
      "episode: 42   score: 1.0   memory length: 6753   epsilon: 1.0   global_step: 6753   average_q: 0.028967779879639676   average loss: 0.0\n",
      "episode: 43   score: 1.0   memory length: 6910   epsilon: 1.0   global_step: 6910   average_q: 0.02802860287202012   average loss: 0.0\n",
      "episode: 44   score: 0.0   memory length: 7033   epsilon: 1.0   global_step: 7033   average_q: 0.02900292722856611   average loss: 0.0\n",
      "episode: 45   score: 2.0   memory length: 7221   epsilon: 1.0   global_step: 7221   average_q: 0.028677964949623703   average loss: 0.0\n",
      "episode: 46   score: 0.0   memory length: 7337   epsilon: 1.0   global_step: 7337   average_q: 0.029092073520838188   average loss: 0.0\n",
      "episode: 47   score: 0.0   memory length: 7448   epsilon: 1.0   global_step: 7448   average_q: 0.029443487978062115   average loss: 0.0\n",
      "episode: 48   score: 1.0   memory length: 7587   epsilon: 1.0   global_step: 7587   average_q: 0.028110315728423405   average loss: 0.0\n",
      "episode: 49   score: 3.0   memory length: 7802   epsilon: 1.0   global_step: 7802   average_q: 0.027898666747780732   average loss: 0.0\n",
      "episode: 50   score: 2.0   memory length: 8014   epsilon: 1.0   global_step: 8014   average_q: 0.02861882755005697   average loss: 0.0\n",
      "episode: 51   score: 0.0   memory length: 8138   epsilon: 1.0   global_step: 8138   average_q: 0.029351234135608518   average loss: 0.0\n",
      "episode: 52   score: 1.0   memory length: 8292   epsilon: 1.0   global_step: 8292   average_q: 0.029111899483900566   average loss: 0.0\n",
      "episode: 53   score: 0.0   memory length: 8415   epsilon: 1.0   global_step: 8415   average_q: 0.02919242343282312   average loss: 0.0\n",
      "episode: 54   score: 1.0   memory length: 8581   epsilon: 1.0   global_step: 8581   average_q: 0.02887722502002515   average loss: 0.0\n",
      "episode: 55   score: 0.0   memory length: 8705   epsilon: 1.0   global_step: 8705   average_q: 0.029288641402437803   average loss: 0.0\n",
      "episode: 56   score: 1.0   memory length: 8856   epsilon: 1.0   global_step: 8856   average_q: 0.027990748624730583   average loss: 0.0\n",
      "episode: 57   score: 3.0   memory length: 9081   epsilon: 1.0   global_step: 9081   average_q: 0.028225416375531092   average loss: 0.0\n",
      "episode: 58   score: 2.0   memory length: 9264   epsilon: 1.0   global_step: 9264   average_q: 0.027839726335852525   average loss: 0.0\n",
      "episode: 59   score: 2.0   memory length: 9463   epsilon: 1.0   global_step: 9463   average_q: 0.028542004123180358   average loss: 0.0\n",
      "episode: 60   score: 0.0   memory length: 9599   epsilon: 1.0   global_step: 9599   average_q: 0.029378851492177036   average loss: 0.0\n",
      "episode: 61   score: 0.0   memory length: 9719   epsilon: 1.0   global_step: 9719   average_q: 0.029018475596482556   average loss: 0.0\n",
      "episode: 62   score: 0.0   memory length: 9854   epsilon: 1.0   global_step: 9854   average_q: 0.029390740049658   average loss: 0.0\n",
      "episode: 63   score: 1.0   memory length: 10016   epsilon: 1.0   global_step: 10016   average_q: 0.02898645000877204   average loss: 0.0\n",
      "episode: 64   score: 1.0   memory length: 10173   epsilon: 1.0   global_step: 10173   average_q: 0.028361910693110174   average loss: 0.0\n",
      "episode: 65   score: 1.0   memory length: 10301   epsilon: 1.0   global_step: 10301   average_q: 0.02824116259580478   average loss: 0.0\n",
      "episode: 66   score: 1.0   memory length: 10452   epsilon: 1.0   global_step: 10452   average_q: 0.029079352881734733   average loss: 0.0\n",
      "episode: 67   score: 0.0   memory length: 10578   epsilon: 1.0   global_step: 10578   average_q: 0.029327538130538806   average loss: 0.0\n",
      "episode: 68   score: 2.0   memory length: 10752   epsilon: 1.0   global_step: 10752   average_q: 0.027710494285599255   average loss: 0.0\n",
      "episode: 69   score: 1.0   memory length: 10903   epsilon: 1.0   global_step: 10903   average_q: 0.028410029665425125   average loss: 0.0\n",
      "episode: 70   score: 2.0   memory length: 11121   epsilon: 1.0   global_step: 11121   average_q: 0.02939543433897539   average loss: 0.0\n",
      "episode: 71   score: 0.0   memory length: 11226   epsilon: 1.0   global_step: 11226   average_q: 0.029372839931221237   average loss: 0.0\n",
      "episode: 72   score: 2.0   memory length: 11423   epsilon: 1.0   global_step: 11423   average_q: 0.02930481358417097   average loss: 0.0\n",
      "episode: 73   score: 2.0   memory length: 11617   epsilon: 1.0   global_step: 11617   average_q: 0.029656248090347063   average loss: 0.0\n",
      "episode: 74   score: 0.0   memory length: 11741   epsilon: 1.0   global_step: 11741   average_q: 0.029370362059243264   average loss: 0.0\n",
      "episode: 75   score: 1.0   memory length: 11914   epsilon: 1.0   global_step: 11914   average_q: 0.02895332749050132   average loss: 0.0\n",
      "episode: 76   score: 1.0   memory length: 12056   epsilon: 1.0   global_step: 12056   average_q: 0.02762353860996139   average loss: 0.0\n",
      "episode: 77   score: 2.0   memory length: 12238   epsilon: 1.0   global_step: 12238   average_q: 0.0294327087864116   average loss: 0.0\n",
      "episode: 78   score: 0.0   memory length: 12361   epsilon: 1.0   global_step: 12361   average_q: 0.029222187093966377   average loss: 0.0\n",
      "episode: 79   score: 0.0   memory length: 12468   epsilon: 1.0   global_step: 12468   average_q: 0.02950275670214791   average loss: 0.0\n",
      "episode: 80   score: 1.0   memory length: 12615   epsilon: 1.0   global_step: 12615   average_q: 0.02881325055293891   average loss: 0.0\n",
      "episode: 81   score: 0.0   memory length: 12724   epsilon: 1.0   global_step: 12724   average_q: 0.029137541787750132   average loss: 0.0\n",
      "episode: 82   score: 1.0   memory length: 12881   epsilon: 1.0   global_step: 12881   average_q: 0.02937267789510405   average loss: 0.0\n",
      "episode: 83   score: 0.0   memory length: 13005   epsilon: 1.0   global_step: 13005   average_q: 0.029309459316033508   average loss: 0.0\n",
      "episode: 84   score: 0.0   memory length: 13124   epsilon: 1.0   global_step: 13124   average_q: 0.029295810506123454   average loss: 0.0\n",
      "episode: 85   score: 2.0   memory length: 13324   epsilon: 1.0   global_step: 13324   average_q: 0.02872883852571249   average loss: 0.0\n",
      "episode: 86   score: 1.0   memory length: 13446   epsilon: 1.0   global_step: 13446   average_q: 0.027867832129485296   average loss: 0.0\n",
      "episode: 87   score: 2.0   memory length: 13627   epsilon: 1.0   global_step: 13627   average_q: 0.027446005050895624   average loss: 0.0\n",
      "episode: 88   score: 2.0   memory length: 13834   epsilon: 1.0   global_step: 13834   average_q: 0.029660062405510224   average loss: 0.0\n",
      "episode: 89   score: 3.0   memory length: 14080   epsilon: 1.0   global_step: 14080   average_q: 0.027245019691261817   average loss: 0.0\n",
      "episode: 90   score: 0.0   memory length: 14182   epsilon: 1.0   global_step: 14182   average_q: 0.02931537774994093   average loss: 0.0\n",
      "episode: 91   score: 1.0   memory length: 14341   epsilon: 1.0   global_step: 14341   average_q: 0.028973514823325025   average loss: 0.0\n",
      "episode: 92   score: 1.0   memory length: 14511   epsilon: 1.0   global_step: 14511   average_q: 0.028922563736491342   average loss: 0.0\n",
      "episode: 93   score: 2.0   memory length: 14698   epsilon: 1.0   global_step: 14698   average_q: 0.02859171381329789   average loss: 0.0\n",
      "episode: 94   score: 0.0   memory length: 14824   epsilon: 1.0   global_step: 14824   average_q: 0.0292365477080383   average loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 95   score: 0.0   memory length: 14927   epsilon: 1.0   global_step: 14927   average_q: 0.029094408636966957   average loss: 0.0\n",
      "episode: 96   score: 0.0   memory length: 15050   epsilon: 1.0   global_step: 15050   average_q: 0.029411338527149302   average loss: 0.0\n",
      "episode: 97   score: 1.0   memory length: 15223   epsilon: 1.0   global_step: 15223   average_q: 0.028792982178099582   average loss: 0.0\n",
      "episode: 98   score: 0.0   memory length: 15333   epsilon: 1.0   global_step: 15333   average_q: 0.029251669110222298   average loss: 0.0\n",
      "episode: 99   score: 0.0   memory length: 15431   epsilon: 1.0   global_step: 15431   average_q: 0.029503097225512778   average loss: 0.0\n",
      "episode: 100   score: 1.0   memory length: 15597   epsilon: 1.0   global_step: 15597   average_q: 0.02892823055027479   average loss: 0.0\n",
      "episode: 101   score: 0.0   memory length: 15705   epsilon: 1.0   global_step: 15705   average_q: 0.02922414144915011   average loss: 0.0\n",
      "episode: 102   score: 1.0   memory length: 15879   epsilon: 1.0   global_step: 15879   average_q: 0.029236282221972942   average loss: 0.0\n",
      "episode: 103   score: 0.0   memory length: 15997   epsilon: 1.0   global_step: 15997   average_q: 0.029572312814830724   average loss: 0.0\n",
      "episode: 104   score: 0.0   memory length: 16124   epsilon: 1.0   global_step: 16124   average_q: 0.029326923440877846   average loss: 0.0\n",
      "episode: 105   score: 0.0   memory length: 16245   epsilon: 1.0   global_step: 16245   average_q: 0.02906895907641935   average loss: 0.0\n",
      "episode: 106   score: 0.0   memory length: 16369   epsilon: 1.0   global_step: 16369   average_q: 0.029137588947290374   average loss: 0.0\n",
      "episode: 107   score: 1.0   memory length: 16512   epsilon: 1.0   global_step: 16512   average_q: 0.029302014975802048   average loss: 0.0\n",
      "episode: 108   score: 0.0   memory length: 16623   epsilon: 1.0   global_step: 16623   average_q: 0.029109307925577636   average loss: 0.0\n",
      "episode: 109   score: 0.0   memory length: 16727   epsilon: 1.0   global_step: 16727   average_q: 0.0292429537512362   average loss: 0.0\n",
      "episode: 110   score: 0.0   memory length: 16842   epsilon: 1.0   global_step: 16842   average_q: 0.02924372879383357   average loss: 0.0\n",
      "episode: 111   score: 0.0   memory length: 16961   epsilon: 1.0   global_step: 16961   average_q: 0.029408933751347687   average loss: 0.0\n",
      "episode: 112   score: 1.0   memory length: 17128   epsilon: 1.0   global_step: 17128   average_q: 0.027670307441832062   average loss: 0.0\n",
      "episode: 113   score: 1.0   memory length: 17305   epsilon: 1.0   global_step: 17305   average_q: 0.027786765394911254   average loss: 0.0\n",
      "episode: 114   score: 0.0   memory length: 17413   epsilon: 1.0   global_step: 17413   average_q: 0.029301272463743335   average loss: 0.0\n",
      "episode: 115   score: 1.0   memory length: 17547   epsilon: 1.0   global_step: 17547   average_q: 0.029042720739076388   average loss: 0.0\n",
      "episode: 116   score: 0.0   memory length: 17652   epsilon: 1.0   global_step: 17652   average_q: 0.02912276985035056   average loss: 0.0\n",
      "episode: 117   score: 0.0   memory length: 17773   epsilon: 1.0   global_step: 17773   average_q: 0.029163569381291218   average loss: 0.0\n",
      "episode: 118   score: 2.0   memory length: 17952   epsilon: 1.0   global_step: 17952   average_q: 0.029096359418257656   average loss: 0.0\n",
      "episode: 119   score: 0.0   memory length: 18071   epsilon: 1.0   global_step: 18071   average_q: 0.029383783455656357   average loss: 0.0\n",
      "episode: 120   score: 6.0   memory length: 18387   epsilon: 1.0   global_step: 18387   average_q: 0.027927399147301912   average loss: 0.0\n",
      "episode: 121   score: 2.0   memory length: 18580   epsilon: 1.0   global_step: 18580   average_q: 0.028843700055785747   average loss: 0.0\n",
      "episode: 122   score: 2.0   memory length: 18780   epsilon: 1.0   global_step: 18780   average_q: 0.02824059972539544   average loss: 0.0\n",
      "episode: 123   score: 2.0   memory length: 18951   epsilon: 1.0   global_step: 18951   average_q: 0.028468367812490604   average loss: 0.0\n",
      "episode: 124   score: 1.0   memory length: 19100   epsilon: 1.0   global_step: 19100   average_q: 0.02888501576779273   average loss: 0.0\n",
      "episode: 125   score: 1.0   memory length: 19256   epsilon: 1.0   global_step: 19256   average_q: 0.028398340078405082   average loss: 0.0\n",
      "episode: 126   score: 0.0   memory length: 19377   epsilon: 1.0   global_step: 19377   average_q: 0.029280400242317806   average loss: 0.0\n",
      "episode: 127   score: 2.0   memory length: 19567   epsilon: 1.0   global_step: 19567   average_q: 0.029161777661034935   average loss: 0.0\n",
      "episode: 128   score: 3.0   memory length: 19826   epsilon: 1.0   global_step: 19826   average_q: 0.029165920265680576   average loss: 0.0\n",
      "episode: 129   score: 2.0   memory length: 20020   epsilon: 1.0   global_step: 20020   average_q: 0.027964145838062174   average loss: 0.0\n",
      "episode: 130   score: 1.0   memory length: 20163   epsilon: 1.0   global_step: 20163   average_q: 0.028641351921991867   average loss: 0.0\n",
      "episode: 131   score: 1.0   memory length: 20320   epsilon: 1.0   global_step: 20320   average_q: 0.029198811893725092   average loss: 0.0\n",
      "episode: 132   score: 1.0   memory length: 20476   epsilon: 1.0   global_step: 20476   average_q: 0.028626565833408862   average loss: 0.0\n",
      "episode: 133   score: 2.0   memory length: 20682   epsilon: 1.0   global_step: 20682   average_q: 0.029596560010776936   average loss: 0.0\n",
      "episode: 134   score: 1.0   memory length: 20823   epsilon: 1.0   global_step: 20823   average_q: 0.028855763098343888   average loss: 0.0\n",
      "episode: 135   score: 1.0   memory length: 20962   epsilon: 1.0   global_step: 20962   average_q: 0.027973452006741395   average loss: 0.0\n",
      "episode: 136   score: 0.0   memory length: 21068   epsilon: 1.0   global_step: 21068   average_q: 0.029165757486139827   average loss: 0.0\n",
      "episode: 137   score: 3.0   memory length: 21283   epsilon: 1.0   global_step: 21283   average_q: 0.029221898343327432   average loss: 0.0\n",
      "episode: 138   score: 0.0   memory length: 21397   epsilon: 1.0   global_step: 21397   average_q: 0.02944056488769619   average loss: 0.0\n",
      "episode: 139   score: 1.0   memory length: 21558   epsilon: 1.0   global_step: 21558   average_q: 0.028976287496108446   average loss: 0.0\n",
      "episode: 140   score: 1.0   memory length: 21728   epsilon: 1.0   global_step: 21728   average_q: 0.028767489598077886   average loss: 0.0\n",
      "episode: 141   score: 3.0   memory length: 21959   epsilon: 1.0   global_step: 21959   average_q: 0.027953667671004417   average loss: 0.0\n",
      "episode: 142   score: 3.0   memory length: 22210   epsilon: 1.0   global_step: 22210   average_q: 0.027841422832997672   average loss: 0.0\n",
      "episode: 143   score: 2.0   memory length: 22408   epsilon: 1.0   global_step: 22408   average_q: 0.027389921690102178   average loss: 0.0\n",
      "episode: 144   score: 1.0   memory length: 22579   epsilon: 1.0   global_step: 22579   average_q: 0.027814312222582554   average loss: 0.0\n",
      "episode: 145   score: 3.0   memory length: 22783   epsilon: 1.0   global_step: 22783   average_q: 0.028103935979671923   average loss: 0.0\n",
      "episode: 146   score: 2.0   memory length: 22993   epsilon: 1.0   global_step: 22993   average_q: 0.0278943561638395   average loss: 0.0\n",
      "episode: 147   score: 2.0   memory length: 23152   epsilon: 1.0   global_step: 23152   average_q: 0.027770873088881654   average loss: 0.0\n",
      "episode: 148   score: 1.0   memory length: 23306   epsilon: 1.0   global_step: 23306   average_q: 0.02885185835229886   average loss: 0.0\n",
      "episode: 149   score: 4.0   memory length: 23571   epsilon: 1.0   global_step: 23571   average_q: 0.028203747287954925   average loss: 0.0\n",
      "episode: 150   score: 0.0   memory length: 23686   epsilon: 1.0   global_step: 23686   average_q: 0.029204886017934136   average loss: 0.0\n",
      "episode: 151   score: 1.0   memory length: 23835   epsilon: 1.0   global_step: 23835   average_q: 0.028242991074619677   average loss: 0.0\n",
      "episode: 152   score: 3.0   memory length: 24074   epsilon: 1.0   global_step: 24074   average_q: 0.02728881688484587   average loss: 0.0\n",
      "episode: 153   score: 1.0   memory length: 24214   epsilon: 1.0   global_step: 24214   average_q: 0.02830901357478329   average loss: 0.0\n",
      "episode: 154   score: 0.0   memory length: 24318   epsilon: 1.0   global_step: 24318   average_q: 0.0293917260490931   average loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 155   score: 1.0   memory length: 24467   epsilon: 1.0   global_step: 24467   average_q: 0.02770098961339701   average loss: 0.0\n",
      "episode: 156   score: 1.0   memory length: 24624   epsilon: 1.0   global_step: 24624   average_q: 0.02876213841899565   average loss: 0.0\n",
      "episode: 157   score: 1.0   memory length: 24777   epsilon: 1.0   global_step: 24777   average_q: 0.028402287439972747   average loss: 0.0\n",
      "episode: 158   score: 4.0   memory length: 25043   epsilon: 1.0   global_step: 25043   average_q: 0.028381545327715856   average loss: 0.0\n",
      "episode: 159   score: 2.0   memory length: 25232   epsilon: 1.0   global_step: 25232   average_q: 0.028842222566405933   average loss: 0.0\n",
      "episode: 160   score: 0.0   memory length: 25331   epsilon: 1.0   global_step: 25331   average_q: 0.029099708046726507   average loss: 0.0\n",
      "episode: 161   score: 3.0   memory length: 25568   epsilon: 1.0   global_step: 25568   average_q: 0.029402025460505285   average loss: 0.0\n",
      "episode: 162   score: 1.0   memory length: 25722   epsilon: 1.0   global_step: 25722   average_q: 0.028818203934601376   average loss: 0.0\n",
      "episode: 163   score: 0.0   memory length: 25854   epsilon: 1.0   global_step: 25854   average_q: 0.02913810380480506   average loss: 0.0\n",
      "episode: 164   score: 0.0   memory length: 25969   epsilon: 1.0   global_step: 25969   average_q: 0.029394672697652943   average loss: 0.0\n",
      "episode: 165   score: 4.0   memory length: 26291   epsilon: 1.0   global_step: 26291   average_q: 0.02905157707076265   average loss: 0.0\n",
      "episode: 166   score: 1.0   memory length: 26465   epsilon: 1.0   global_step: 26465   average_q: 0.029227181048742657   average loss: 0.0\n",
      "episode: 167   score: 6.0   memory length: 26811   epsilon: 1.0   global_step: 26811   average_q: 0.028353647517331073   average loss: 0.0\n",
      "episode: 168   score: 1.0   memory length: 26959   epsilon: 1.0   global_step: 26959   average_q: 0.027688694287192176   average loss: 0.0\n",
      "episode: 169   score: 0.0   memory length: 27058   epsilon: 1.0   global_step: 27058   average_q: 0.02918056654508668   average loss: 0.0\n",
      "episode: 170   score: 1.0   memory length: 27198   epsilon: 1.0   global_step: 27198   average_q: 0.027176094866756883   average loss: 0.0\n",
      "episode: 171   score: 2.0   memory length: 27370   epsilon: 1.0   global_step: 27370   average_q: 0.027377914561521867   average loss: 0.0\n",
      "episode: 172   score: 1.0   memory length: 27523   epsilon: 1.0   global_step: 27523   average_q: 0.0284569796929562   average loss: 0.0\n",
      "episode: 173   score: 1.0   memory length: 27680   epsilon: 1.0   global_step: 27680   average_q: 0.028933295019113334   average loss: 0.0\n",
      "episode: 174   score: 1.0   memory length: 27822   epsilon: 1.0   global_step: 27822   average_q: 0.027645699338803828   average loss: 0.0\n",
      "episode: 175   score: 1.0   memory length: 27973   epsilon: 1.0   global_step: 27973   average_q: 0.028035529648626087   average loss: 0.0\n",
      "episode: 176   score: 1.0   memory length: 28138   epsilon: 1.0   global_step: 28138   average_q: 0.029122580870082883   average loss: 0.0\n",
      "episode: 177   score: 2.0   memory length: 28321   epsilon: 1.0   global_step: 28321   average_q: 0.02793878285326267   average loss: 0.0\n",
      "episode: 178   score: 1.0   memory length: 28480   epsilon: 1.0   global_step: 28480   average_q: 0.028880640817513258   average loss: 0.0\n",
      "episode: 179   score: 1.0   memory length: 28623   epsilon: 1.0   global_step: 28623   average_q: 0.028201129430761702   average loss: 0.0\n",
      "episode: 180   score: 2.0   memory length: 28841   epsilon: 1.0   global_step: 28841   average_q: 0.02842268645934282   average loss: 0.0\n",
      "episode: 181   score: 1.0   memory length: 28994   epsilon: 1.0   global_step: 28994   average_q: 0.027969913362385402   average loss: 0.0\n",
      "episode: 182   score: 0.0   memory length: 29115   epsilon: 1.0   global_step: 29115   average_q: 0.029207955922715922   average loss: 0.0\n",
      "episode: 183   score: 0.0   memory length: 29224   epsilon: 1.0   global_step: 29224   average_q: 0.02929960551816936   average loss: 0.0\n",
      "episode: 184   score: 3.0   memory length: 29467   epsilon: 1.0   global_step: 29467   average_q: 0.029628796426295744   average loss: 0.0\n",
      "episode: 185   score: 1.0   memory length: 29637   epsilon: 1.0   global_step: 29637   average_q: 0.028921289303723504   average loss: 0.0\n",
      "episode: 186   score: 0.0   memory length: 29751   epsilon: 1.0   global_step: 29751   average_q: 0.02933512815976875   average loss: 0.0\n",
      "episode: 187   score: 1.0   memory length: 29933   epsilon: 1.0   global_step: 29933   average_q: 0.028764621160187565   average loss: 0.0\n",
      "episode: 188   score: 0.0   memory length: 30037   epsilon: 1.0   global_step: 30037   average_q: 0.029320707293943718   average loss: 0.0\n",
      "episode: 189   score: 1.0   memory length: 30165   epsilon: 1.0   global_step: 30165   average_q: 0.027964347857050598   average loss: 0.0\n",
      "episode: 190   score: 2.0   memory length: 30353   epsilon: 1.0   global_step: 30353   average_q: 0.028845637729589608   average loss: 0.0\n",
      "episode: 191   score: 1.0   memory length: 30525   epsilon: 1.0   global_step: 30525   average_q: 0.027721931768018147   average loss: 0.0\n",
      "episode: 192   score: 1.0   memory length: 30675   epsilon: 1.0   global_step: 30675   average_q: 0.029194283535083135   average loss: 0.0\n",
      "episode: 193   score: 0.0   memory length: 30799   epsilon: 1.0   global_step: 30799   average_q: 0.029238006926231807   average loss: 0.0\n",
      "episode: 194   score: 1.0   memory length: 30956   epsilon: 1.0   global_step: 30956   average_q: 0.029158235343683298   average loss: 0.0\n",
      "episode: 195   score: 0.0   memory length: 31058   epsilon: 1.0   global_step: 31058   average_q: 0.0293874638337715   average loss: 0.0\n",
      "episode: 196   score: 2.0   memory length: 31258   epsilon: 1.0   global_step: 31258   average_q: 0.029127111127600074   average loss: 0.0\n",
      "episode: 197   score: 3.0   memory length: 31463   epsilon: 1.0   global_step: 31463   average_q: 0.02818698250665897   average loss: 0.0\n",
      "episode: 198   score: 0.0   memory length: 31579   epsilon: 1.0   global_step: 31579   average_q: 0.029195375210637677   average loss: 0.0\n",
      "episode: 199   score: 3.0   memory length: 31796   epsilon: 1.0   global_step: 31796   average_q: 0.0277241713491865   average loss: 0.0\n",
      "episode: 200   score: 1.0   memory length: 31956   epsilon: 1.0   global_step: 31956   average_q: 0.029069232440087946   average loss: 0.0\n",
      "episode: 201   score: 1.0   memory length: 32129   epsilon: 1.0   global_step: 32129   average_q: 0.029229627857576906   average loss: 0.0\n",
      "episode: 202   score: 0.0   memory length: 32248   epsilon: 1.0   global_step: 32248   average_q: 0.029351000760157567   average loss: 0.0\n",
      "episode: 203   score: 2.0   memory length: 32439   epsilon: 1.0   global_step: 32439   average_q: 0.02873914497685058   average loss: 0.0\n",
      "episode: 204   score: 0.0   memory length: 32546   epsilon: 1.0   global_step: 32546   average_q: 0.02898713591221337   average loss: 0.0\n",
      "episode: 205   score: 1.0   memory length: 32701   epsilon: 1.0   global_step: 32701   average_q: 0.029167112888347717   average loss: 0.0\n",
      "episode: 206   score: 1.0   memory length: 32865   epsilon: 1.0   global_step: 32865   average_q: 0.028931657579250453   average loss: 0.0\n",
      "episode: 207   score: 0.0   memory length: 32960   epsilon: 1.0   global_step: 32960   average_q: 0.02927039708746107   average loss: 0.0\n",
      "episode: 208   score: 2.0   memory length: 33141   epsilon: 1.0   global_step: 33141   average_q: 0.028591939901614058   average loss: 0.0\n",
      "episode: 209   score: 2.0   memory length: 33346   epsilon: 1.0   global_step: 33346   average_q: 0.029258219479787642   average loss: 0.0\n",
      "episode: 210   score: 4.0   memory length: 33649   epsilon: 1.0   global_step: 33649   average_q: 0.029077665892617142   average loss: 0.0\n",
      "episode: 211   score: 1.0   memory length: 33789   epsilon: 1.0   global_step: 33789   average_q: 0.028719471567975625   average loss: 0.0\n",
      "episode: 212   score: 0.0   memory length: 33901   epsilon: 1.0   global_step: 33901   average_q: 0.029178162421365932   average loss: 0.0\n",
      "episode: 213   score: 0.0   memory length: 34026   epsilon: 1.0   global_step: 34026   average_q: 0.02929674868285656   average loss: 0.0\n",
      "episode: 214   score: 0.0   memory length: 34124   epsilon: 1.0   global_step: 34124   average_q: 0.029099286362832905   average loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 215   score: 0.0   memory length: 34244   epsilon: 1.0   global_step: 34244   average_q: 0.029284543124958873   average loss: 0.0\n",
      "episode: 216   score: 4.0   memory length: 34498   epsilon: 1.0   global_step: 34498   average_q: 0.027645418083104563   average loss: 0.0\n",
      "episode: 217   score: 2.0   memory length: 34720   epsilon: 1.0   global_step: 34720   average_q: 0.029313266042385017   average loss: 0.0\n",
      "episode: 218   score: 2.0   memory length: 34894   epsilon: 1.0   global_step: 34894   average_q: 0.028542264953426932   average loss: 0.0\n",
      "episode: 219   score: 2.0   memory length: 35086   epsilon: 1.0   global_step: 35086   average_q: 0.02923311178650086   average loss: 0.0\n",
      "episode: 220   score: 0.0   memory length: 35189   epsilon: 1.0   global_step: 35189   average_q: 0.029238161043200678   average loss: 0.0\n",
      "episode: 221   score: 0.0   memory length: 35295   epsilon: 1.0   global_step: 35295   average_q: 0.02920690735907487   average loss: 0.0\n",
      "episode: 222   score: 0.0   memory length: 35412   epsilon: 1.0   global_step: 35412   average_q: 0.02922666112645569   average loss: 0.0\n",
      "episode: 223   score: 0.0   memory length: 35542   epsilon: 1.0   global_step: 35542   average_q: 0.029350440548016474   average loss: 0.0\n",
      "episode: 224   score: 0.0   memory length: 35642   epsilon: 1.0   global_step: 35642   average_q: 0.029373459927737714   average loss: 0.0\n",
      "episode: 225   score: 0.0   memory length: 35750   epsilon: 1.0   global_step: 35750   average_q: 0.029109928412018   average loss: 0.0\n",
      "episode: 226   score: 2.0   memory length: 35951   epsilon: 1.0   global_step: 35951   average_q: 0.029237827054451947   average loss: 0.0\n",
      "episode: 227   score: 0.0   memory length: 36066   epsilon: 1.0   global_step: 36066   average_q: 0.02899663511501706   average loss: 0.0\n",
      "episode: 228   score: 3.0   memory length: 36265   epsilon: 1.0   global_step: 36265   average_q: 0.0302137376076013   average loss: 0.0\n",
      "episode: 229   score: 1.0   memory length: 36433   epsilon: 1.0   global_step: 36433   average_q: 0.028929671849168483   average loss: 0.0\n",
      "episode: 230   score: 1.0   memory length: 36578   epsilon: 1.0   global_step: 36578   average_q: 0.0290118596034831   average loss: 0.0\n",
      "episode: 231   score: 0.0   memory length: 36696   epsilon: 1.0   global_step: 36696   average_q: 0.02930033609460471   average loss: 0.0\n",
      "episode: 232   score: 1.0   memory length: 36847   epsilon: 1.0   global_step: 36847   average_q: 0.028685838058097473   average loss: 0.0\n",
      "episode: 233   score: 1.0   memory length: 37021   epsilon: 1.0   global_step: 37021   average_q: 0.02941273572458618   average loss: 0.0\n",
      "episode: 234   score: 3.0   memory length: 37265   epsilon: 1.0   global_step: 37265   average_q: 0.030198239011415204   average loss: 0.0\n",
      "episode: 235   score: 4.0   memory length: 37521   epsilon: 1.0   global_step: 37521   average_q: 0.028841857703810092   average loss: 0.0\n",
      "episode: 236   score: 3.0   memory length: 37721   epsilon: 1.0   global_step: 37721   average_q: 0.025701671652495862   average loss: 0.0\n",
      "episode: 237   score: 2.0   memory length: 37926   epsilon: 1.0   global_step: 37926   average_q: 0.028648508112968468   average loss: 0.0\n",
      "episode: 238   score: 0.0   memory length: 38038   epsilon: 1.0   global_step: 38038   average_q: 0.02900728483551315   average loss: 0.0\n",
      "episode: 239   score: 0.0   memory length: 38156   epsilon: 1.0   global_step: 38156   average_q: 0.029398417968492387   average loss: 0.0\n",
      "episode: 240   score: 2.0   memory length: 38345   epsilon: 1.0   global_step: 38345   average_q: 0.029136711780829404   average loss: 0.0\n",
      "episode: 241   score: 0.0   memory length: 38441   epsilon: 1.0   global_step: 38441   average_q: 0.029013370260751497   average loss: 0.0\n",
      "episode: 242   score: 1.0   memory length: 38601   epsilon: 1.0   global_step: 38601   average_q: 0.028959917102474718   average loss: 0.0\n",
      "episode: 243   score: 2.0   memory length: 38811   epsilon: 1.0   global_step: 38811   average_q: 0.028828180785335247   average loss: 0.0\n",
      "episode: 244   score: 0.0   memory length: 38921   epsilon: 1.0   global_step: 38921   average_q: 0.02928565601733598   average loss: 0.0\n",
      "episode: 245   score: 2.0   memory length: 39097   epsilon: 1.0   global_step: 39097   average_q: 0.028550087347288023   average loss: 0.0\n",
      "episode: 246   score: 0.0   memory length: 39230   epsilon: 1.0   global_step: 39230   average_q: 0.029518750909351764   average loss: 0.0\n",
      "episode: 247   score: 0.0   memory length: 39351   epsilon: 1.0   global_step: 39351   average_q: 0.029253447289801827   average loss: 0.0\n",
      "episode: 248   score: 1.0   memory length: 39483   epsilon: 1.0   global_step: 39483   average_q: 0.0278133861438343   average loss: 0.0\n",
      "episode: 249   score: 1.0   memory length: 39651   epsilon: 1.0   global_step: 39651   average_q: 0.029204450658566895   average loss: 0.0\n",
      "episode: 250   score: 2.0   memory length: 39808   epsilon: 1.0   global_step: 39808   average_q: 0.027649283812494034   average loss: 0.0\n",
      "episode: 251   score: 0.0   memory length: 39915   epsilon: 1.0   global_step: 39915   average_q: 0.029165671685727958   average loss: 0.0\n",
      "episode: 252   score: 2.0   memory length: 40146   epsilon: 1.0   global_step: 40146   average_q: 0.027907031680985447   average loss: 0.0\n",
      "episode: 253   score: 0.0   memory length: 40283   epsilon: 1.0   global_step: 40283   average_q: 0.029204493905179693   average loss: 0.0\n",
      "episode: 254   score: 0.0   memory length: 40394   epsilon: 1.0   global_step: 40394   average_q: 0.02917671389877796   average loss: 0.0\n",
      "episode: 255   score: 0.0   memory length: 40505   epsilon: 1.0   global_step: 40505   average_q: 0.029509841825242515   average loss: 0.0\n",
      "episode: 256   score: 0.0   memory length: 40613   epsilon: 1.0   global_step: 40613   average_q: 0.029017876799183863   average loss: 0.0\n",
      "episode: 257   score: 0.0   memory length: 40723   epsilon: 1.0   global_step: 40723   average_q: 0.02937686321410266   average loss: 0.0\n",
      "episode: 258   score: 0.0   memory length: 40830   epsilon: 1.0   global_step: 40830   average_q: 0.029442519976574683   average loss: 0.0\n",
      "episode: 259   score: 0.0   memory length: 40948   epsilon: 1.0   global_step: 40948   average_q: 0.029424809061495933   average loss: 0.0\n",
      "episode: 260   score: 2.0   memory length: 41131   epsilon: 1.0   global_step: 41131   average_q: 0.028763401836075418   average loss: 0.0\n",
      "episode: 261   score: 2.0   memory length: 41346   epsilon: 1.0   global_step: 41346   average_q: 0.028480761992030364   average loss: 0.0\n",
      "episode: 262   score: 0.0   memory length: 41460   epsilon: 1.0   global_step: 41460   average_q: 0.029294514848867005   average loss: 0.0\n",
      "episode: 263   score: 1.0   memory length: 41612   epsilon: 1.0   global_step: 41612   average_q: 0.02905883080031919   average loss: 0.0\n",
      "episode: 264   score: 3.0   memory length: 41812   epsilon: 1.0   global_step: 41812   average_q: 0.028530881013721227   average loss: 0.0\n",
      "episode: 265   score: 2.0   memory length: 42020   epsilon: 1.0   global_step: 42020   average_q: 0.02924083376554056   average loss: 0.0\n",
      "episode: 266   score: 2.0   memory length: 42238   epsilon: 1.0   global_step: 42238   average_q: 0.029525256126162108   average loss: 0.0\n",
      "episode: 267   score: 3.0   memory length: 42460   epsilon: 1.0   global_step: 42460   average_q: 0.027624627239666542   average loss: 0.0\n",
      "episode: 268   score: 1.0   memory length: 42623   epsilon: 1.0   global_step: 42623   average_q: 0.029016313525888085   average loss: 0.0\n",
      "episode: 269   score: 0.0   memory length: 42723   epsilon: 1.0   global_step: 42723   average_q: 0.029276414979249238   average loss: 0.0\n",
      "episode: 270   score: 2.0   memory length: 42902   epsilon: 1.0   global_step: 42902   average_q: 0.028746159934548026   average loss: 0.0\n",
      "episode: 271   score: 3.0   memory length: 43120   epsilon: 1.0   global_step: 43120   average_q: 0.030046528829005333   average loss: 0.0\n",
      "episode: 272   score: 2.0   memory length: 43302   epsilon: 1.0   global_step: 43302   average_q: 0.028559736579984098   average loss: 0.0\n",
      "episode: 273   score: 2.0   memory length: 43503   epsilon: 1.0   global_step: 43503   average_q: 0.029201000854743656   average loss: 0.0\n",
      "episode: 274   score: 1.0   memory length: 43675   epsilon: 1.0   global_step: 43675   average_q: 0.02901462114654308   average loss: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 275   score: 2.0   memory length: 43861   epsilon: 1.0   global_step: 43861   average_q: 0.028864039809152645   average loss: 0.0\n",
      "episode: 276   score: 1.0   memory length: 44020   epsilon: 1.0   global_step: 44020   average_q: 0.028372657385730894   average loss: 0.0\n",
      "episode: 277   score: 2.0   memory length: 44194   epsilon: 1.0   global_step: 44194   average_q: 0.028533698123847616   average loss: 0.0\n",
      "episode: 278   score: 1.0   memory length: 44359   epsilon: 1.0   global_step: 44359   average_q: 0.028859353415442237   average loss: 0.0\n",
      "episode: 279   score: 2.0   memory length: 44560   epsilon: 1.0   global_step: 44560   average_q: 0.028358955584948334   average loss: 0.0\n",
      "episode: 280   score: 0.0   memory length: 44680   epsilon: 1.0   global_step: 44680   average_q: 0.02915838295593858   average loss: 0.0\n",
      "episode: 281   score: 1.0   memory length: 44832   epsilon: 1.0   global_step: 44832   average_q: 0.028047456357039903   average loss: 0.0\n",
      "episode: 282   score: 1.0   memory length: 44998   epsilon: 1.0   global_step: 44998   average_q: 0.02916835316916905   average loss: 0.0\n",
      "episode: 283   score: 1.0   memory length: 45160   epsilon: 1.0   global_step: 45160   average_q: 0.028679384666000618   average loss: 0.0\n",
      "episode: 284   score: 2.0   memory length: 45347   epsilon: 1.0   global_step: 45347   average_q: 0.02984990731359803   average loss: 0.0\n",
      "episode: 285   score: 2.0   memory length: 45545   epsilon: 1.0   global_step: 45545   average_q: 0.028586367794284313   average loss: 0.0\n",
      "episode: 286   score: 0.0   memory length: 45648   epsilon: 1.0   global_step: 45648   average_q: 0.029413398174406254   average loss: 0.0\n",
      "episode: 287   score: 1.0   memory length: 45801   epsilon: 1.0   global_step: 45801   average_q: 0.029793601495280764   average loss: 0.0\n",
      "episode: 288   score: 3.0   memory length: 46031   epsilon: 1.0   global_step: 46031   average_q: 0.028371675045269988   average loss: 0.0\n",
      "episode: 289   score: 4.0   memory length: 46318   epsilon: 1.0   global_step: 46318   average_q: 0.028378389314959274   average loss: 0.0\n",
      "episode: 290   score: 0.0   memory length: 46432   epsilon: 1.0   global_step: 46432   average_q: 0.029266907114600928   average loss: 0.0\n",
      "episode: 291   score: 0.0   memory length: 46550   epsilon: 1.0   global_step: 46550   average_q: 0.02935560930015172   average loss: 0.0\n",
      "episode: 292   score: 1.0   memory length: 46705   epsilon: 1.0   global_step: 46705   average_q: 0.028550042151924103   average loss: 0.0\n",
      "episode: 293   score: 1.0   memory length: 46858   epsilon: 1.0   global_step: 46858   average_q: 0.028941727212928477   average loss: 0.0\n",
      "episode: 294   score: 1.0   memory length: 47006   epsilon: 1.0   global_step: 47006   average_q: 0.028287939676964604   average loss: 0.0\n",
      "episode: 295   score: 2.0   memory length: 47198   epsilon: 1.0   global_step: 47198   average_q: 0.028773281616546836   average loss: 0.0\n",
      "episode: 296   score: 1.0   memory length: 47338   epsilon: 1.0   global_step: 47338   average_q: 0.02799032949177282   average loss: 0.0\n",
      "episode: 297   score: 0.0   memory length: 47458   epsilon: 1.0   global_step: 47458   average_q: 0.029263921035453676   average loss: 0.0\n",
      "episode: 298   score: 3.0   memory length: 47683   epsilon: 1.0   global_step: 47683   average_q: 0.029049422012435065   average loss: 0.0\n",
      "episode: 299   score: 1.0   memory length: 47839   epsilon: 1.0   global_step: 47839   average_q: 0.028898254323464174   average loss: 0.0\n",
      "episode: 300   score: 0.0   memory length: 47962   epsilon: 1.0   global_step: 47962   average_q: 0.02914337370150942   average loss: 0.0\n",
      "episode: 301   score: 0.0   memory length: 48080   epsilon: 1.0   global_step: 48080   average_q: 0.029172663987314298   average loss: 0.0\n",
      "episode: 302   score: 1.0   memory length: 48214   epsilon: 1.0   global_step: 48214   average_q: 0.028206718932670443   average loss: 0.0\n",
      "episode: 303   score: 0.0   memory length: 48346   epsilon: 1.0   global_step: 48346   average_q: 0.029260476938251293   average loss: 0.0\n",
      "episode: 304   score: 1.0   memory length: 48497   epsilon: 1.0   global_step: 48497   average_q: 0.028373318471458575   average loss: 0.0\n",
      "episode: 305   score: 0.0   memory length: 48594   epsilon: 1.0   global_step: 48594   average_q: 0.029250353478740172   average loss: 0.0\n",
      "episode: 306   score: 2.0   memory length: 48785   epsilon: 1.0   global_step: 48785   average_q: 0.027957021439184694   average loss: 0.0\n",
      "episode: 307   score: 2.0   memory length: 48960   epsilon: 1.0   global_step: 48960   average_q: 0.028654118755034038   average loss: 0.0\n",
      "episode: 308   score: 1.0   memory length: 49126   epsilon: 1.0   global_step: 49126   average_q: 0.02905813189425382   average loss: 0.0\n",
      "episode: 309   score: 1.0   memory length: 49268   epsilon: 1.0   global_step: 49268   average_q: 0.028091566374814008   average loss: 0.0\n",
      "episode: 310   score: 1.0   memory length: 49434   epsilon: 1.0   global_step: 49434   average_q: 0.02918773275766387   average loss: 0.0\n",
      "episode: 311   score: 4.0   memory length: 49697   epsilon: 1.0   global_step: 49697   average_q: 0.025859824045359407   average loss: 0.0\n",
      "episode: 312   score: 1.0   memory length: 49850   epsilon: 1.0   global_step: 49850   average_q: 0.029082584091358714   average loss: 0.0\n",
      "episode: 313   score: 0.0   memory length: 49967   epsilon: 1.0   global_step: 49967   average_q: 0.02927851708781006   average loss: 0.0\n",
      "episode: 314   score: 0.0   memory length: 50080   epsilon: 0.9999271000000024   global_step: 50080   average_q: 0.6993600470302379   average loss: 0.27528987355105683\n",
      "episode: 315   score: 1.0   memory length: 50236   epsilon: 0.999786700000007   global_step: 50236   average_q: 1.1587165399239614   average loss: 0.3514905484636797\n",
      "episode: 316   score: 0.0   memory length: 50333   epsilon: 0.9996994000000099   global_step: 50333   average_q: 1.0307141321221578   average loss: 0.33430890779049355\n",
      "episode: 317   score: 1.0   memory length: 50459   epsilon: 0.9995860000000136   global_step: 50459   average_q: 1.1283129273899017   average loss: 0.32779397787862763\n",
      "episode: 318   score: 3.0   memory length: 50683   epsilon: 0.9993844000000203   global_step: 50683   average_q: 1.1792951401855265   average loss: 0.3762546124932961\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from collections import deque\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "\n",
    "EPISODES = 1000\n",
    "\n",
    "\n",
    "# 브레이크아웃에서의 DQN 에이전트\n",
    "class DQNAgent:\n",
    "    def __init__(self, action_size):\n",
    "        self.render = False\n",
    "        self.load_model = False\n",
    "        # 상태와 행동의 크기 정의\n",
    "        self.state_size = (84, 84, 4)\n",
    "        self.action_size = action_size\n",
    "        # DQN 하이퍼파라미터\n",
    "        self.epsilon = 1.\n",
    "        self.epsilon_start, self.epsilon_end = 1.0, 0.1\n",
    "        self.exploration_steps = 1000000.\n",
    "        self.epsilon_decay_step = (self.epsilon_start - self.epsilon_end) \\\n",
    "                                  / self.exploration_steps\n",
    "        self.batch_size = 32\n",
    "        self.train_start = 50000\n",
    "        self.update_target_rate = 10000\n",
    "        self.discount_factor = 0.99\n",
    "        # 리플레이 메모리, 최대 크기 400000\n",
    "        self.memory = deque(maxlen=400000)\n",
    "        self.no_op_steps = 30\n",
    "        # 모델과 타겟모델을 생성하고 타겟모델 초기화\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "        self.optimizer = self.optimizer()\n",
    "\n",
    "        # 텐서보드 설정\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        K.set_session(self.sess)\n",
    "\n",
    "        self.avg_q_max, self.avg_loss = 0, 0\n",
    "        self.summary_placeholders, self.update_ops, self.summary_op = \\\n",
    "            self.setup_summary()\n",
    "        self.summary_writer = tf.summary.FileWriter(\n",
    "            'summary/breakout_dqn', self.sess.graph)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./save_model/breakout_dqn.h5\")\n",
    "\n",
    "    # Huber Loss를 이용하기 위해 최적화 함수를 직접 정의\n",
    "    def optimizer(self):\n",
    "        a = K.placeholder(shape=(None,), dtype='int32')\n",
    "        y = K.placeholder(shape=(None,), dtype='float32')\n",
    "\n",
    "        prediction = self.model.output\n",
    "\n",
    "        a_one_hot = K.one_hot(a, self.action_size)\n",
    "        q_value = K.sum(prediction * a_one_hot, axis=1)\n",
    "        error = K.abs(y - q_value)\n",
    "\n",
    "        quadratic_part = K.clip(error, 0.0, 1.0)\n",
    "        linear_part = error - quadratic_part\n",
    "        loss = K.mean(0.5 * K.square(quadratic_part) + linear_part)\n",
    "\n",
    "        optimizer = RMSprop(lr=0.00025, epsilon=0.01)\n",
    "        updates = optimizer.get_updates(self.model.trainable_weights, [], loss)\n",
    "        train = K.function([self.model.input, a, y], [loss], updates=updates)\n",
    "\n",
    "        return train\n",
    "\n",
    "    # 상태가 입력, 큐함수가 출력인 인공신경망 생성\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu',\n",
    "                         input_shape=self.state_size))\n",
    "        model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(self.action_size))\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    # 타겟 모델을 모델의 가중치로 업데이트\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    # 입실론 탐욕 정책으로 행동 선택\n",
    "    def get_action(self, history):\n",
    "        history = np.float32(history / 255.0)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(history)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    # 샘플 <s, a, r, s'>을 리플레이 메모리에 저장\n",
    "    def append_sample(self, history, action, reward, next_history, dead):\n",
    "        self.memory.append((history, action, reward, next_history, dead))\n",
    "\n",
    "    # 리플레이 메모리에서 무작위로 추출한 배치로 모델 학습\n",
    "    def train_model(self):\n",
    "        if self.epsilon > self.epsilon_end:\n",
    "            self.epsilon -= self.epsilon_decay_step\n",
    "\n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "        history = np.zeros((self.batch_size, self.state_size[0],\n",
    "                            self.state_size[1], self.state_size[2]))\n",
    "        next_history = np.zeros((self.batch_size, self.state_size[0],\n",
    "                                 self.state_size[1], self.state_size[2]))\n",
    "        target = np.zeros((self.batch_size,))\n",
    "        action, reward, dead = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            history[i] = np.float32(mini_batch[i][0] / 255.)\n",
    "            next_history[i] = np.float32(mini_batch[i][3] / 255.)\n",
    "            action.append(mini_batch[i][1])\n",
    "            reward.append(mini_batch[i][2])\n",
    "            dead.append(mini_batch[i][4])\n",
    "\n",
    "        target_value = self.target_model.predict(next_history)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            if dead[i]:\n",
    "                target[i] = reward[i]\n",
    "            else:\n",
    "                target[i] = reward[i] + self.discount_factor * \\\n",
    "                                        np.amax(target_value[i])\n",
    "\n",
    "        loss = self.optimizer([history, action, target])\n",
    "        self.avg_loss += loss[0]\n",
    "\n",
    "    # 각 에피소드 당 학습 정보를 기록\n",
    "    def setup_summary(self):\n",
    "        episode_total_reward = tf.Variable(0.)\n",
    "        episode_avg_max_q = tf.Variable(0.)\n",
    "        episode_duration = tf.Variable(0.)\n",
    "        episode_avg_loss = tf.Variable(0.)\n",
    "\n",
    "        tf.summary.scalar('Total Reward/Episode', episode_total_reward)\n",
    "        tf.summary.scalar('Average Max Q/Episode', episode_avg_max_q)\n",
    "        tf.summary.scalar('Duration/Episode', episode_duration)\n",
    "        tf.summary.scalar('Average Loss/Episode', episode_avg_loss)\n",
    "\n",
    "        summary_vars = [episode_total_reward, episode_avg_max_q,\n",
    "                        episode_duration, episode_avg_loss]\n",
    "        summary_placeholders = [tf.placeholder(tf.float32) for _ in\n",
    "                                range(len(summary_vars))]\n",
    "        update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in\n",
    "                      range(len(summary_vars))]\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        return summary_placeholders, update_ops, summary_op\n",
    "\n",
    "\n",
    "# 학습속도를 높이기 위해 흑백화면으로 전처리\n",
    "def pre_processing(observe):\n",
    "    processed_observe = np.uint8(\n",
    "        resize(rgb2gray(observe), (84, 84), mode='constant') * 255)\n",
    "    return processed_observe\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 환경과 DQN 에이전트 생성\n",
    "    env = gym.make('BreakoutDeterministic-v4')\n",
    "    agent = DQNAgent(action_size=3)\n",
    "\n",
    "    scores, episodes, global_step = [], [], 0\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        dead = False\n",
    "\n",
    "        step, score, start_life = 0, 0, 5\n",
    "        observe = env.reset()\n",
    "\n",
    "        for _ in range(random.randint(1, agent.no_op_steps)):\n",
    "            observe, _, _, _ = env.step(1)\n",
    "\n",
    "        state = pre_processing(observe)\n",
    "        history = np.stack((state, state, state, state), axis=2)\n",
    "        history = np.reshape([history], (1, 84, 84, 4))\n",
    "\n",
    "        while not done:\n",
    "            if agent.render:\n",
    "                env.render()\n",
    "            global_step += 1\n",
    "            step += 1\n",
    "\n",
    "            # 바로 전 4개의 상태로 행동을 선택\n",
    "            action = agent.get_action(history)\n",
    "            # 1: 정지, 2: 왼쪽, 3: 오른쪽\n",
    "            if action == 0:\n",
    "                real_action = 1\n",
    "            elif action == 1:\n",
    "                real_action = 2\n",
    "            else:\n",
    "                real_action = 3\n",
    "\n",
    "            # 선택한 행동으로 환경에서 한 타임스텝 진행\n",
    "            observe, reward, done, info = env.step(real_action)\n",
    "            # 각 타임스텝마다 상태 전처리\n",
    "            next_state = pre_processing(observe)\n",
    "            next_state = np.reshape([next_state], (1, 84, 84, 1))\n",
    "            next_history = np.append(next_state, history[:, :, :, :3], axis=3)\n",
    "\n",
    "            agent.avg_q_max += np.amax(\n",
    "                agent.model.predict(np.float32(history / 255.))[0])\n",
    "\n",
    "            if start_life > info['ale.lives']:\n",
    "                dead = True\n",
    "                start_life = info['ale.lives']\n",
    "\n",
    "            reward = np.clip(reward, -1., 1.)\n",
    "            # 샘플 <s, a, r, s'>을 리플레이 메모리에 저장 후 학습\n",
    "            agent.append_sample(history, action, reward, next_history, dead)\n",
    "\n",
    "            if len(agent.memory) >= agent.train_start:\n",
    "                agent.train_model()\n",
    "\n",
    "            # 일정 시간마다 타겟모델을 모델의 가중치로 업데이트\n",
    "            if global_step % agent.update_target_rate == 0:\n",
    "                agent.update_target_model()\n",
    "\n",
    "            score += reward\n",
    "\n",
    "            if dead:\n",
    "                dead = False\n",
    "            else:\n",
    "                history = next_history\n",
    "\n",
    "            if done:\n",
    "                # 각 에피소드 당 학습 정보를 기록\n",
    "                if global_step > agent.train_start:\n",
    "                    stats = [score, agent.avg_q_max / float(step), step,\n",
    "                             agent.avg_loss / float(step)]\n",
    "                    for i in range(len(stats)):\n",
    "                        agent.sess.run(agent.update_ops[i], feed_dict={\n",
    "                            agent.summary_placeholders[i]: float(stats[i])\n",
    "                        })\n",
    "                    summary_str = agent.sess.run(agent.summary_op)\n",
    "                    agent.summary_writer.add_summary(summary_str, e + 1)\n",
    "\n",
    "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                      len(agent.memory), \"  epsilon:\", agent.epsilon,\n",
    "                      \"  global_step:\", global_step, \"  average_q:\",\n",
    "                      agent.avg_q_max / float(step), \"  average loss:\",\n",
    "                      agent.avg_loss / float(step))\n",
    "\n",
    "                agent.avg_q_max, agent.avg_loss = 0, 0\n",
    "\n",
    "        # 1000 에피소드마다 모델 저장\n",
    "        if e % 1000 == 0:\n",
    "            agent.model.save_weights(\"./save_model/breakout_dqn.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
